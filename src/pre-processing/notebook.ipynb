{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f72ca48",
   "metadata": {},
   "source": [
    "# VisCPU: data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a5dc2a",
   "metadata": {},
   "source": [
    "Metrics to calculate:\n",
    "- IPC (Instructions Per Cycle): how much CPU cycles instructions require to execute?\n",
    "    - How to calculate? Instructions divided by CPU cycles;\n",
    "    - How to interpret? In general, values higher than one are good;\n",
    "    - https://stackoverflow.com/questions/51438407/how-to-correctly-measure-ipc-instructions-per-cycle-with-perf\n",
    "    \n",
    "- https://stackoverflow.com/questions/22165299/what-are-stalled-cycles-frontend-and-stalled-cycles-backend-in-perf-stat-resul\n",
    "\n",
    "- How well cache is working?\n",
    "    - How to calculate? Cache misses divided by instructions;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982b259",
   "metadata": {},
   "source": [
    "## Dependencies and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960d0a3",
   "metadata": {},
   "source": [
    "Install and import required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d1e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install psutil\n",
    "!conda install -c plotly plotly-orca -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabed656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from viscpu import utils, perf_record\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98dcefb",
   "metadata": {},
   "source": [
    "## perf stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426fb02",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe2fd1",
   "metadata": {},
   "source": [
    "Load the two datasets that will be compared. We use the first dataset as base for comparison. For example: if the first experiment has 10 cache misses and the second has 15 cache misses, this means that the number of cache misses increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15939861",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = \"../applications/simple-ff-test/data/perf-test-1.csv\"\n",
    "dataset_2 = \"../applications/simple-ff-test/data/perf-test-2.csv\"\n",
    "\n",
    "column_names=[\"time\", \"cpu\", \"counter_value\", \"ignore_1\", \"event\",\n",
    "              \"ignore_2\", \"ignore_3\", \"ignore_4\", \"ignore_5\", \"ignore_6\"]\n",
    "usecols=[\"time\", \"cpu\", \"counter_value\", \"event\"]\n",
    "\n",
    "df_1 = pd.read_csv(dataset_1, skiprows=1, header=None, names=column_names, usecols=usecols)\n",
    "df_1[\"time\"] = df_1[\"time\"].round(4)\n",
    "df_2 = pd.read_csv(dataset_2, skiprows=1, header=None, names=column_names, usecols=usecols)\n",
    "df_2[\"time\"] = df_2[\"time\"].round(4)\n",
    "\n",
    "df_1[\"counter_value\"] = df_1[\"counter_value\"].replace([\"<not counted>\"], 0).astype(int)\n",
    "df_2[\"counter_value\"] = df_2[\"counter_value\"].replace([\"<not counted>\"], 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f775ae3c",
   "metadata": {},
   "source": [
    "Define captured events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96f4b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = list(df_1[\"event\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118c868b",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9eddd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    \"events\": events,\n",
    "    \"dataset-1\": {\"raw\": {}, \"aggregated\": {}},\n",
    "    \"dataset-2\": {\"raw\": {}, \"aggregated\": {}},\n",
    "    \"comparison-1-2\": {},\n",
    "    \"comparison-2-1\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efdc14",
   "metadata": {},
   "source": [
    "Create the setup of the CPUs. Here you can choose how many CPUs will be shown on each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae44a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_labels, cpu_setup = utils.get_cpu_setup(df_1[\"cpu\"].unique(), cpus_per_row=4)\n",
    "\n",
    "output[\"cpu_labels\"] = cpu_labels\n",
    "output[\"cpu_setup\"] = cpu_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d229288",
   "metadata": {},
   "source": [
    "Load data from each captured event and write in `output`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3599d772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing event 'cpu-cycles'...\n",
      "Finished event 'cpu-cycles'.\n",
      "Processing event 'instructions'...\n",
      "Finished event 'instructions'.\n",
      "Processing event 'cache-misses'...\n",
      "Finished event 'cache-misses'.\n",
      "Processing event 'cache-references'...\n",
      "Finished event 'cache-references'.\n",
      "Processing event 'L1-dcache-load-misses'...\n",
      "Finished event 'L1-dcache-load-misses'.\n",
      "Processing event 'L1-dcache-loads'...\n",
      "Finished event 'L1-dcache-loads'.\n",
      "Processing event 'L1-dcache-stores'...\n",
      "Finished event 'L1-dcache-stores'.\n",
      "Processing event 'L1-icache-load-misses'...\n",
      "Finished event 'L1-icache-load-misses'.\n",
      "Processing event 'LLC-loads'...\n",
      "Finished event 'LLC-loads'.\n",
      "Processing event 'LLC-load-misses'...\n",
      "Finished event 'LLC-load-misses'.\n",
      "Processing event 'LLC-stores'...\n",
      "Finished event 'LLC-stores'.\n",
      "Processing event 'LLC-store-misses'...\n",
      "Finished event 'LLC-store-misses'.\n",
      "Processing event 'mem-loads'...\n",
      "Finished event 'mem-loads'.\n",
      "Processing event 'mem-stores'...\n",
      "Finished event 'mem-stores'.\n",
      "Processing event 'Joules'...\n",
      "Finished event 'Joules'.\n",
      "Processing event 'branch-misses'...\n",
      "Finished event 'branch-misses'.\n",
      "Processing event 'branch-instructions'...\n",
      "Finished event 'branch-instructions'.\n",
      "Processing event 'power:cpu_idle'...\n",
      "Finished event 'power:cpu_idle'.\n",
      "Processing event 'power:cpu_frequency'...\n",
      "Finished event 'power:cpu_frequency'.\n"
     ]
    }
   ],
   "source": [
    "for event in events:\n",
    "    print(f\"Processing event '{event}'...\")\n",
    "    times, captures = utils.get_event_data(df_1, cpu_setup, event)\n",
    "    output[\"dataset-1\"][\"raw\"][event] = {\n",
    "        \"captures\": captures,\n",
    "        \"captures_min\": float(df_1[df_1[\"event\"] == event][\"counter_value\"].min()),\n",
    "        \"captures_max\": float(df_1[df_1[\"event\"] == event][\"counter_value\"].max())\n",
    "    }\n",
    "    \n",
    "    times, captures = utils.get_event_data(df_2, cpu_setup, event)\n",
    "    output[\"dataset-2\"][\"raw\"][event] = {\n",
    "        \"captures\": captures,\n",
    "        \"captures_min\": float(df_2[df_2[\"event\"] == event][\"counter_value\"].min()),\n",
    "        \"captures_max\": float(df_2[df_2[\"event\"] == event][\"counter_value\"].max())\n",
    "    }\n",
    "    print(f\"Finished event '{event}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a4ab90",
   "metadata": {},
   "source": [
    "Aggregate time series of events. This will allow to compare the overall performance of the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73929061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing event 'cpu-cycles'...\n",
      "Finished event 'cpu-cycles'.\n",
      "Processing event 'instructions'...\n",
      "Finished event 'instructions'.\n",
      "Processing event 'cache-misses'...\n",
      "Finished event 'cache-misses'.\n",
      "Processing event 'cache-references'...\n",
      "Finished event 'cache-references'.\n",
      "Processing event 'L1-dcache-load-misses'...\n",
      "Finished event 'L1-dcache-load-misses'.\n",
      "Processing event 'L1-dcache-loads'...\n",
      "Finished event 'L1-dcache-loads'.\n",
      "Processing event 'L1-dcache-stores'...\n",
      "Finished event 'L1-dcache-stores'.\n",
      "Processing event 'L1-icache-load-misses'...\n",
      "Finished event 'L1-icache-load-misses'.\n",
      "Processing event 'LLC-loads'...\n",
      "Finished event 'LLC-loads'.\n",
      "Processing event 'LLC-load-misses'...\n",
      "Finished event 'LLC-load-misses'.\n",
      "Processing event 'LLC-stores'...\n",
      "Finished event 'LLC-stores'.\n",
      "Processing event 'LLC-store-misses'...\n",
      "Finished event 'LLC-store-misses'.\n",
      "Processing event 'mem-loads'...\n",
      "Finished event 'mem-loads'.\n",
      "Processing event 'mem-stores'...\n",
      "Finished event 'mem-stores'.\n",
      "Processing event 'Joules'...\n",
      "Finished event 'Joules'.\n",
      "Processing event 'branch-misses'...\n",
      "Finished event 'branch-misses'.\n",
      "Processing event 'branch-instructions'...\n",
      "Finished event 'branch-instructions'.\n",
      "Processing event 'power:cpu_idle'...\n",
      "Finished event 'power:cpu_idle'.\n",
      "Processing event 'power:cpu_frequency'...\n",
      "Finished event 'power:cpu_frequency'.\n"
     ]
    }
   ],
   "source": [
    "for event in events:\n",
    "    print(f\"Processing event '{event}'...\")\n",
    "    df_1_aggr = df_1[df_1[\"event\"] == event].groupby([\"cpu\"], as_index=False)[\"counter_value\"]\n",
    "    df_2_aggr = df_2[df_2[\"event\"] == event].groupby([\"cpu\"], as_index=False)[\"counter_value\"]\n",
    "    \n",
    "    if event not in output[\"dataset-1\"][\"aggregated\"]:\n",
    "        output[\"dataset-1\"][\"aggregated\"][event] = {\n",
    "            \"mean\": {},\n",
    "            \"mean_relative\": {},\n",
    "            \"sum\": {},\n",
    "            \"sum_relative\": {},\n",
    "        }\n",
    "        output[\"dataset-2\"][\"aggregated\"][event] = {\n",
    "            \"mean\": {},\n",
    "            \"mean_relative\": {},\n",
    "            \"sum\": {},\n",
    "            \"sum_relative\": {}\n",
    "        }\n",
    "    \n",
    "    if event not in output[\"comparison-1-2\"]:\n",
    "        output[\"comparison-1-2\"][event] = {}\n",
    "        output[\"comparison-2-1\"][event] = {}\n",
    "    \n",
    "    a = utils.transform_cpu_data(df_1_aggr.mean(), cpu_setup)\n",
    "    a_sum = np.sum(a)\n",
    "    b = utils.transform_cpu_data(df_2_aggr.mean(), cpu_setup)\n",
    "    b_sum = np.sum(b)\n",
    "    output[\"dataset-1\"][\"aggregated\"][event][\"mean\"] = a\n",
    "    output[\"dataset-1\"][\"aggregated\"][event][\"mean_relative\"] = a if a_sum <= 0 else ((np.array(a) / a_sum) * 100).tolist()\n",
    "    output[\"dataset-2\"][\"aggregated\"][event][\"mean\"] = b\n",
    "    output[\"dataset-2\"][\"aggregated\"][event][\"mean_relative\"] = b if b_sum <= 0 else ((np.array(b) / b_sum) * 100).tolist()\n",
    "    \n",
    "    output[\"comparison-1-2\"][event][\"mean\"] = (np.array(a) - np.array(b)).tolist()\n",
    "    output[\"comparison-1-2\"][event][\"mean_relative\"] = b if b_sum <= 0 else ((np.array(a) / a_sum - np.array(b) / b_sum) * 100).tolist()\n",
    "    output[\"comparison-1-2\"][event][\"mean_value\"] = 0 if np.mean(a) <= 0 else ((np.mean(b) / np.mean(a)) - 1) * 100\n",
    "    output[\"comparison-2-1\"][event][\"mean\"] = (np.array(b) - np.array(a)).tolist()\n",
    "    output[\"comparison-2-1\"][event][\"mean_relative\"] = a if a_sum <= 0 else ((np.array(b) / b_sum - np.array(a) / a_sum) * 100).tolist()\n",
    "    output[\"comparison-2-1\"][event][\"mean_value\"] = 0 if np.mean(b) <= 0 else ((np.mean(a) / np.mean(b)) - 1) * 100\n",
    "    \n",
    "    a = utils.transform_cpu_data(df_1_aggr.sum(), cpu_setup)\n",
    "    a_sum = np.sum(a)\n",
    "    b = utils.transform_cpu_data(df_2_aggr.sum(), cpu_setup)\n",
    "    b_sum = np.sum(b)\n",
    "    output[\"dataset-1\"][\"aggregated\"][event][\"sum\"] = a\n",
    "    output[\"dataset-1\"][\"aggregated\"][event][\"sum_relative\"] = a if a_sum <= 0 else ((np.array(a) / a_sum) * 100).tolist()\n",
    "    output[\"dataset-2\"][\"aggregated\"][event][\"sum\"] = b\n",
    "    output[\"dataset-2\"][\"aggregated\"][event][\"sum_relative\"] = b if b_sum <= 0 else ((np.array(b) / b_sum) * 100).tolist()\n",
    "    \n",
    "    output[\"comparison-1-2\"][event][\"sum\"] = (np.array(a) - np.array(b)).tolist()\n",
    "    output[\"comparison-1-2\"][event][\"sum_relative\"] = b if b_sum <= 0 else (((np.array(a) / a_sum) - (np.array(b) / b_sum)) * 100).tolist()\n",
    "    output[\"comparison-1-2\"][event][\"sum_value\"] = 0 if np.sum(b) <= 0 else ((np.sum(a) / np.sum(b)) - 1) * 100\n",
    "    output[\"comparison-2-1\"][event][\"sum\"] = (np.array(b) - np.array(a)).tolist()\n",
    "    output[\"comparison-2-1\"][event][\"sum_relative\"] = a if a_sum <= 0 else (((np.array(b) / b_sum) - (np.array(a) / a_sum)) * 100).tolist()\n",
    "    output[\"comparison-2-1\"][event][\"sum_value\"] = 0 if np.sum(a) <= 0 else ((np.sum(b) / np.sum(a)) - 1) * 100\n",
    "    \n",
    "    print(f\"Finished event '{event}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de07dc3f",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402eaa7",
   "metadata": {},
   "source": [
    "Write `output` to a JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef36167a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "\n",
    "with open(\"data/simple-ff-test-1-2.json\", \"w\") as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c514e",
   "metadata": {},
   "source": [
    "## perf record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f888b",
   "metadata": {},
   "source": [
    "### Parse datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fb5db960",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_1 = \"../applications/simple-ff-test/data/perf-record-1.txt\"\n",
    "dataset_1_output = \"../applications/simple-ff-test/data/perf-record-1.csv\"\n",
    "dataset_2 = \"../applications/simple-ff-test/data/perf-record-2.txt\"\n",
    "dataset_2_output = \"../applications/simple-ff-test/data/perf-record-2.csv\"\n",
    "\n",
    "# perf_record.parse_record_dataset(dataset_1, dataset_1_output)\n",
    "# perf_record.parse_record_dataset(dataset_2, dataset_2_output)\n",
    "\n",
    "df_1 = pd.read_csv(dataset_1_output)\n",
    "df_2 = pd.read_csv(dataset_2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e115bdb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    time_second                  event  cpu    counter  \\\n",
      "0             0  L1-dcache-load-misses    0       2148   \n",
      "1             0  L1-dcache-load-misses    1    2055373   \n",
      "2             0  L1-dcache-load-misses    2        331   \n",
      "3             0  L1-dcache-load-misses    3        119   \n",
      "4             0  L1-dcache-load-misses    4    1836128   \n",
      "5             0  L1-dcache-load-misses    5        240   \n",
      "6             0  L1-dcache-load-misses    6        114   \n",
      "7             0  L1-dcache-load-misses    7       1439   \n",
      "8             0  L1-dcache-load-misses    8        166   \n",
      "9             0  L1-dcache-load-misses    9    1029360   \n",
      "10            0  L1-dcache-load-misses   10        362   \n",
      "11            0  L1-dcache-load-misses   11      39609   \n",
      "12            0        L1-dcache-loads    1  406915287   \n",
      "13            0        L1-dcache-loads    4  118291750   \n",
      "14            0        L1-dcache-loads    9  368596511   \n",
      "15            0       L1-dcache-stores    1  147452749   \n",
      "16            0       L1-dcache-stores    4   47457898   \n",
      "17            0       L1-dcache-stores    9  173284994   \n",
      "18            0  L1-icache-load-misses    1     380224   \n",
      "19            0  L1-icache-load-misses    4    6176341   \n",
      "\n",
      "                                                stack  \n",
      "0   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "1   [__GI___sched_setaffinity_new+0xb|ff_mapThread...  \n",
      "2   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "3   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "4   [__GI___sched_setaffinity_new+0xb|ff_mapThread...  \n",
      "5   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "6   [__GI___clone+0x35, __GI___clone+0x35, [unknow...  \n",
      "7   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "8   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "9   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "10  [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "11  [_start+0x0, _start+0x0, [unknown]|_start+0x0,...  \n",
      "12  [ff::ticks_wait+0x1a|ff::ff_loadbalancer::lose...  \n",
      "13  [getticks+0x1a|ff::ticks_wait+0x19, getticks+0...  \n",
      "14  [ff::uSWSR_Ptr_Buffer::pop+0x62|ff::ff_node::g...  \n",
      "15  [ff::ff_loadbalancer::schedule_task+0x23e|ff::...  \n",
      "16  [getticks+0x6|ff::ticks_wait+0x19|ff::ff_node:...  \n",
      "17  [ff::ticks_wait+0x1e|ff::ff_gatherer::losetime...  \n",
      "18  [getticks+0x9|ff::ticks_wait+0x19|ff::ff_loadb...  \n",
      "19  [__GI___libc_write+0x4f|__GI___libc_write+0x4f...  \n",
      "    time_second                  event  cpu    counter  \\\n",
      "0             0  L1-dcache-load-misses    0    1331804   \n",
      "1             0  L1-dcache-load-misses    1     866160   \n",
      "2             0  L1-dcache-load-misses    2     230654   \n",
      "3             0  L1-dcache-load-misses    3     173324   \n",
      "4             0  L1-dcache-load-misses    4     139478   \n",
      "5             0  L1-dcache-load-misses    5     188027   \n",
      "6             0  L1-dcache-load-misses    6     247540   \n",
      "7             0  L1-dcache-load-misses    7     204943   \n",
      "8             0  L1-dcache-load-misses    8     238682   \n",
      "9             0  L1-dcache-load-misses    9     273381   \n",
      "10            0  L1-dcache-load-misses   10     231724   \n",
      "11            0  L1-dcache-load-misses   11     185139   \n",
      "12            0        L1-dcache-loads    0  318311724   \n",
      "13            0        L1-dcache-loads    1  249608492   \n",
      "14            0        L1-dcache-loads    2  126494888   \n",
      "15            0        L1-dcache-loads    3   97736761   \n",
      "16            0        L1-dcache-loads    4  111910973   \n",
      "17            0        L1-dcache-loads    5  111251454   \n",
      "18            0        L1-dcache-loads    6   86509803   \n",
      "19            0        L1-dcache-loads    7  106113454   \n",
      "\n",
      "                                                stack  \n",
      "0   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "1   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "2   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "3   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "4   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "5   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "6   [_start+0x0, _start+0x0, _start+0x3, elf_get_d...  \n",
      "7   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "8   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "9   [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "10  [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "11  [__GI___clone+0x35, __GI___clone+0x35, __GI___...  \n",
      "12  [ff::uSWSR_Ptr_Buffer::push+0x5c|ff::ff_node::...  \n",
      "13  [ff::ticks_wait+0x1e|ff::ff_node::losetime_out...  \n",
      "14  [getticks+0x1a|ff::ticks_wait+0x19, ff::ticks_...  \n",
      "15  [ff::ticks_wait+0x2e|ff::ff_node::losetime_out...  \n",
      "16  [ff::ticks_wait+0x2e|ff::ff_node::losetime_out...  \n",
      "17  [ff::ticks_wait+0x22|ff::ff_node::losetime_out...  \n",
      "18  [getticks+0x16|ff::ticks_wait+0x19|ff::ff_node...  \n",
      "19  [ff::ff_node::Pop+0x167|ff::ff_node::thWorker:...  \n"
     ]
    }
   ],
   "source": [
    "df_1[\"time\"] = df_1[\"time\"] - df_1[\"time\"].min()\n",
    "df_1[\"time_second\"] = df_1[\"time\"].apply(lambda x: int(x))\n",
    "df_1 = df_1.groupby([\"time_second\", \"event\", \"cpu\"]).agg({\"counter\": \"sum\", \"stack\": list}).reset_index()\n",
    "print(df_1.head(20))\n",
    "\n",
    "df_2[\"time\"] = df_2[\"time\"] - df_2[\"time\"].min()\n",
    "df_2[\"time_second\"] = df_2[\"time\"].apply(lambda x: int(x))\n",
    "df_2 = df_2.groupby([\"time_second\", \"event\", \"cpu\"]).agg({\"counter\": \"sum\", \"stack\": list}).reset_index()\n",
    "print(df_2.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70eafcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dnn]",
   "language": "python",
   "name": "conda-env-dnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
