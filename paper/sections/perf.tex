\section{Perf}

Perf is a profiling tool included in the Linux kernel. It can be used to capture CPU performance counters, tracepoints, kprobes\footnote{\url{https://www.kernel.org/doc/html/latest/trace/kprobes.html}}, and uprobes\footnote{\url{https://www.kernel.org/doc/html/latest/trace/uprobetracer.html}}~\cite{perf_wiki}. Perf also supports software events, such as page misses. In turn, tracepoints are placed in the source code to collect timestamps and stack traces and performance counters are hardware registers that count events of the CPU, such as instructions executed and cache-misses. Perf has low overhead, as it is integrated into the kernel. Moreover, Perf supports counters in different architectures. Therefore, it can be used to profile applications in different Intel architectures or even in AMD CPUs.

There are several subcommands available in Perf. Below we describe some of the subcommands:

\begin{itemize}
	\item \texttt{perf stat}: gather performance counter statistics from a command;
    \item \texttt{perf record}: run a command and record its profile for later analysis. By default, profile is saved in a file named \texttt{perf.data};
    \item \texttt{perf report}: read \texttt{perf.data} and display the profile recorded in this file;
    \item \texttt{perf script}: read \texttt{perf.data} and display the trace recorded in this file;
	\item \texttt{perf top}: display performance counter profile in real time;
	\item \texttt{perf list}: list events available to be captured in the current architecture;
\end{itemize}

\texttt{perf list} shows events from several sources, such as hardware and software. Hardware events are provided by the processor and its PMUs (Performance Monitoring Unit), which may vary among different companies. Next, we discuss the counters captured in our experiments~\cite{intel_pmu}.

\begin{itemize}
	\item \textbf{cpu-cycles}: number of fetch-decode-execute cycles the CPU executed;
	\item \textbf{instructions}: number of instructions the CPU executed;
	\item \textbf{cache-misses}: number of cache-misses;
	\item \textbf{cache-references}: number of references found in cache;
	\item \textbf{L1-dcache-load-misses}: number of misses when loading data from L1 cache;
	\item \textbf{L1-dcache-loads}: number of data loads from L1 cache;
	\item \textbf{L1-dcache-stores}: number of data stores made in L1 cache;
	\item \textbf{L1-icache-load-misses}: number of misses when loading instructions from L1 cache;
	\item \textbf{L1-icache-loads}: number of instructions load from L1 cache;
	\item \textbf{L1-icache-stores}: number of instructions store made in L1 cache;
	\item \textbf{LLC-loads}: number of references loaded from LLC (Last Level Cache, usually L3);
	\item \textbf{LLC-load-misses}: number of references missed when loading from LLC;
	\item \textbf{LLC-stores}: number of references store made loading in LLC;
	\item \textbf{mem-stores}: number of stores made in the main memory;
	\item \textbf{mem-loads}: number of loads made from the main memory;
	\item \textbf{branch-misses}: number of mispredicted speculative branches;
    \item \textbf{branch-instructions}: number of correct speculative branches;
	\item \textbf{bus-cycles}: number of CPU cycles needed to fetch or write data to the main memory, for example;
\end{itemize}

For this paper, we profiled the person recognition application. The main goal of this application is to recognize is there is a person in a specific image, using OpenCV. To characterize a stream processing application, it is, we cannot predict when data will stop entering the application, we used a video as input.

Towards exploiting parallelism, we use the FastFlow library and compared two mapping policies. In summary, the mapping policy defines in which core threads launched by the application will be placed. We profiled the person recognition application using the default mapping policy os the Linux operating system and the mapping policy proposed by FastFlow.
